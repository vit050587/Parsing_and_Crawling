# Парсинг и Краулинг
![MarkDown](https://github.com/vit050587/Parsing_and_Crawling/blob/master/Parsing.png)
* Базовые знания компьютерных сетей 
* Основы работы с протоколом HTTP 
* Основы работы с Открытыми данными 
* Основы web: HTML/CSS, JavaScript 
* Принципы работы с сервисами RESTful и SOAP 
* Понимание форматов данных JSON, XML, CSV 
* Основы работы с MongoDB
# Урок 1. 
## Основы клиент-серверного взаимодействия. Работа с API
* Узнаем основные принципы сбора данных. Как отправлять GET-запросы при помощи разных инструментов. Как работать с ответами от сервера и API, JSON
# Урок 2. 
## Парсинг HTML. Библиотека Beautiful soup.
* Познакомимся с HTML-кодом страниц Изучим структуру DOM. Рассмотрим основы сбора данных с помощью инструмента Beautiful Soup.
# Урок 3. 
## Система управления базами данных MongoDB в Python
* Узнаем основные принципы работы с реляционными и нереляционными базами данных. Рассмотрим основные операции и методы для формирования запросов. Научимся работать с данными внутри баз.
# Урок 4. 
## Парсинг HTML. XPath
* Узнаем, что такое открытые данные, для чего они нужны и как используются. Научимся работать с CSV в Python и самостоятельно их создавать.
# Урок 5. 
## Selenium в Python
* Узнаем, что такое открытые данные, для чего они нужны и как используются. Научимся работать с CSV в Python и самостоятельно их создавать.
# Урок 6. 
## Фреймворк Scrapy. Знакомство
* Узнаем, что такое открытые данные, для чего они нужны и как используются. Научимся работать с CSV в Python и самостоятельно их создавать.
# Урок 7. 
## Фреймворк Scrapy. Скачивание файлов и фото
* Узнаем, что такое открытые данные, для чего они нужны и как используются. Научимся работать с CSV в Python и самостоятельно их создавать.
# Урок 8. 
## Фреймворк Scrapy. Реализация механизмов клиент-серверного взаимодействия
* Узнаем, что такое открытые данные, для чего они нужны и как используются. Научимся работать с CSV в Python и самостоятельно их создавать.
